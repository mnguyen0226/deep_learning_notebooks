{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d2ae447",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.012068,
     "end_time": "2023-02-17T20:11:43.985721",
     "exception": false,
     "start_time": "2023-02-17T20:11:43.973653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7.3 Using built-in training and evaluation loops\n",
    "- The standard way to build machine learning model is to compile(), fit(), evaluate(), predict()\n",
    "- There are more way to customize the process:\n",
    "    - Provide your own custom metrics.\n",
    "    - Write your own calll backs.\n",
    "    - Monitor and visualize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0ba91d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:11:44.004686Z",
     "iopub.status.busy": "2023-02-17T20:11:44.004234Z",
     "iopub.status.idle": "2023-02-17T20:11:51.653592Z",
     "shell.execute_reply": "2023-02-17T20:11:51.652548Z"
    },
    "papermill": {
     "duration": 7.662779,
     "end_time": "2023-02-17T20:11:51.656816",
     "exception": false,
     "start_time": "2023-02-17T20:11:43.994037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f879b786",
   "metadata": {
    "papermill": {
     "duration": 0.007915,
     "end_time": "2023-02-17T20:11:51.673198",
     "exception": false,
     "start_time": "2023-02-17T20:11:51.665283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## A. ML General Workflow: compile(), fit(), evaluate(), predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f9c8ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:11:51.692550Z",
     "iopub.status.busy": "2023-02-17T20:11:51.691576Z",
     "iopub.status.idle": "2023-02-17T20:11:51.697564Z",
     "shell.execute_reply": "2023-02-17T20:11:51.696704Z"
    },
    "papermill": {
     "duration": 0.018231,
     "end_time": "2023-02-17T20:11:51.699774",
     "exception": false,
     "start_time": "2023-02-17T20:11:51.681543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mnist_model():\n",
    "    # create a model using Functional API\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features) # multi-class classification, single output\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44eed824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:11:51.718893Z",
     "iopub.status.busy": "2023-02-17T20:11:51.718185Z",
     "iopub.status.idle": "2023-02-17T20:11:53.734584Z",
     "shell.execute_reply": "2023-02-17T20:11:53.733638Z"
    },
    "papermill": {
     "duration": 2.028687,
     "end_time": "2023-02-17T20:11:53.737205",
     "exception": false,
     "start_time": "2023-02-17T20:11:51.708518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# flatten images\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "\n",
    "# get the training and validation set\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c34dc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:11:53.760397Z",
     "iopub.status.busy": "2023-02-17T20:11:53.759964Z",
     "iopub.status.idle": "2023-02-17T20:12:37.374661Z",
     "shell.execute_reply": "2023-02-17T20:12:37.373393Z"
    },
    "papermill": {
     "duration": 43.629127,
     "end_time": "2023-02-17T20:12:37.377267",
     "exception": false,
     "start_time": "2023-02-17T20:11:53.748140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 20:11:53.799281: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64::/opt/conda/lib\n",
      "2023-02-17 20:11:53.799346: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2951 - accuracy: 0.9126 - val_loss: 0.1452 - val_accuracy: 0.9580\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1661 - accuracy: 0.9529 - val_loss: 0.1180 - val_accuracy: 0.9678\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1423 - accuracy: 0.9620 - val_loss: 0.1219 - val_accuracy: 0.9692\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1147 - accuracy: 0.9706\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# create a model\n",
    "model = get_mnist_model()\n",
    "\n",
    "# compile the model by specifying its optimizer, loss functionn, and metrics\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# train and validate the model\n",
    "model.fit(train_images, train_labels, epochs=3, validation_data=(val_images, val_labels))\n",
    "\n",
    "# test model\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9129fb",
   "metadata": {
    "papermill": {
     "duration": 0.039202,
     "end_time": "2023-02-17T20:12:37.456278",
     "exception": false,
     "start_time": "2023-02-17T20:12:37.417076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## B. Write your own metrics\n",
    "- Keras has Metric class, however, the variables aren't updated via backpropagation, so we need to write the state-update logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b31319",
   "metadata": {
    "papermill": {
     "duration": 0.039384,
     "end_time": "2023-02-17T20:12:37.535845",
     "exception": false,
     "start_time": "2023-02-17T20:12:37.496461",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Implement a custom metric by subclassing the Metric class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d323ba51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:12:37.616535Z",
     "iopub.status.busy": "2023-02-17T20:12:37.616146Z",
     "iopub.status.idle": "2023-02-17T20:12:37.626661Z",
     "shell.execute_reply": "2023-02-17T20:12:37.625481Z"
    },
    "papermill": {
     "duration": 0.054131,
     "end_time": "2023-02-17T20:12:37.629156",
     "exception": false,
     "start_time": "2023-02-17T20:12:37.575025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\"\n",
    "        )\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \"\"\"Implement state updates\"\"\"\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "        \n",
    "    def result(self):\n",
    "        \"\"\"Return the values of the metrics\"\"\"\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "    \n",
    "    def reset_state(self):\n",
    "        \"\"\"Reset without reinitialize\"\"\"\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b18e66e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:12:37.710880Z",
     "iopub.status.busy": "2023-02-17T20:12:37.710454Z",
     "iopub.status.idle": "2023-02-17T20:13:07.066132Z",
     "shell.execute_reply": "2023-02-17T20:13:07.064803Z"
    },
    "papermill": {
     "duration": 29.400005,
     "end_time": "2023-02-17T20:13:07.069046",
     "exception": false,
     "start_time": "2023-02-17T20:12:37.669041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2971 - accuracy: 0.9124 - rmse: 7.1814 - val_loss: 0.1519 - val_accuracy: 0.9562 - val_rmse: 7.3549\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1671 - accuracy: 0.9528 - rmse: 7.3544 - val_loss: 0.1290 - val_accuracy: 0.9644 - val_rmse: 7.4005\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1409 - accuracy: 0.9626 - rmse: 7.3874 - val_loss: 0.1219 - val_accuracy: 0.9691 - val_rmse: 7.4200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1122 - accuracy: 0.9704 - rmse: 7.4333\n"
     ]
    }
   ],
   "source": [
    "# build a model\n",
    "model = get_mnist_model()\n",
    "\n",
    "# initilize optimizer, loss, metrics\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "\n",
    "# train model\n",
    "model.fit(train_images, train_labels, epochs=3, validation_data=(val_images, val_labels))\n",
    "\n",
    "# test model\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4eda51",
   "metadata": {
    "papermill": {
     "duration": 0.068712,
     "end_time": "2023-02-17T20:13:07.207769",
     "exception": false,
     "start_time": "2023-02-17T20:13:07.139057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## C. Using callbacks\n",
    "- Training your model with `fit()` can take a lot of resource, thus `callback` object is callled by the model at various points during training. The object has access to all the available data about the state of the model and its performance. \n",
    "- It can have some actions:\n",
    "    - interrupt training.\n",
    "    - save a model.\n",
    "    - load a different weight set.\n",
    "    - alter the state of the model\n",
    "- Some examples of using callbacks:\n",
    "    - Model checkpointing: Saving the current state of the model at different points during training.\n",
    "    - Early stopping: Interrupt training when the validation loss is no longer improving.\n",
    "    - Dynamically adjusting the value of certain parameter during training: such as the learning rate of the optimizer.\n",
    "    - Logging training and validationn metrics during training, or visualizing the representations learned by the model as they're updated.\n",
    "- Some of the function calls;\n",
    "```python\n",
    "keras.callbacks.ModelCheckpoint\n",
    "keras.callbacks.EarlyStopping\n",
    "keras.callbacks.LearningRateScheduler\n",
    "keras.callbacks.ReduceLROnPlateau\n",
    "keras.callbacks.CSVLogger\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd25b55",
   "metadata": {
    "papermill": {
     "duration": 0.068591,
     "end_time": "2023-02-17T20:13:07.345491",
     "exception": false,
     "start_time": "2023-02-17T20:13:07.276900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The EarlyStopping & ModelCheckpoint Callbacks\n",
    "- When you are training, there are many things you can't predict such as number of epochs. Previously, we have to retrain from scratch, which is wasteful of resource. A better way is to stop training when you measure that the validation loss is no longer improving.\n",
    "- Let's write the code using callbacks argument in the `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6be45e4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:13:07.486653Z",
     "iopub.status.busy": "2023-02-17T20:13:07.486228Z",
     "iopub.status.idle": "2023-02-17T20:13:07.492692Z",
     "shell.execute_reply": "2023-02-17T20:13:07.491287Z"
    },
    "papermill": {
     "duration": 0.080631,
     "end_time": "2023-02-17T20:13:07.495127",
     "exception": false,
     "start_time": "2023-02-17T20:13:07.414496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# callbackks are passed to the model via fit() which takes a list of call backs\n",
    "callback_list = [\n",
    "    # interrupts training when improvement stops\n",
    "    keras.callbacks.EarlyStopping( \n",
    "        monitor=\"val_accuracy\", # monitors the model's validation accuracy\n",
    "        patience=2,             # innterrupt training when accuracy has stopped improving for 2 epochs\n",
    "    ),\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\", # save the current weights after every epochs\n",
    "        monitor=\"val_loss\",  # don't overwrite the model file unless val_loss has improoved which allow you to keep the best model seen during training\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5fe3920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:13:07.634549Z",
     "iopub.status.busy": "2023-02-17T20:13:07.634093Z",
     "iopub.status.idle": "2023-02-17T20:14:33.245792Z",
     "shell.execute_reply": "2023-02-17T20:14:33.244556Z"
    },
    "papermill": {
     "duration": 85.684425,
     "end_time": "2023-02-17T20:14:33.248425",
     "exception": false,
     "start_time": "2023-02-17T20:13:07.564000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2940 - accuracy: 0.9129 - val_loss: 0.1575 - val_accuracy: 0.9552\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1648 - accuracy: 0.9537 - val_loss: 0.1194 - val_accuracy: 0.9683\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1415 - accuracy: 0.9624 - val_loss: 0.1152 - val_accuracy: 0.9704\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1265 - accuracy: 0.9674 - val_loss: 0.1062 - val_accuracy: 0.9744\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1165 - accuracy: 0.9708 - val_loss: 0.1064 - val_accuracy: 0.9759\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1091 - accuracy: 0.9728 - val_loss: 0.1054 - val_accuracy: 0.9759\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1086 - accuracy: 0.9743 - val_loss: 0.1061 - val_accuracy: 0.9777\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1013 - accuracy: 0.9766 - val_loss: 0.1100 - val_accuracy: 0.9773\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0989 - accuracy: 0.9781 - val_loss: 0.1116 - val_accuracy: 0.9781\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0990 - accuracy: 0.9783 - val_loss: 0.1221 - val_accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f54a86eafd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model\n",
    "model = get_mnist_model()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# train and validate the model\n",
    "model.fit(train_images, train_labels, epochs=10, callbacks=callback_list, validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae0d5f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:14:33.576601Z",
     "iopub.status.busy": "2023-02-17T20:14:33.576197Z",
     "iopub.status.idle": "2023-02-17T20:14:33.581308Z",
     "shell.execute_reply": "2023-02-17T20:14:33.580093Z"
    },
    "papermill": {
     "duration": 0.172835,
     "end_time": "2023-02-17T20:14:33.583809",
     "exception": false,
     "start_time": "2023-02-17T20:14:33.410974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # you can always save the model manually after training\n",
    "# model.save(\"my_checkpoint_path\")\n",
    "\n",
    "# # load the model\n",
    "# model = keras.models.load_model(\"my_checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec1794",
   "metadata": {
    "papermill": {
     "duration": 0.162837,
     "end_time": "2023-02-17T20:14:33.910526",
     "exception": false,
     "start_time": "2023-02-17T20:14:33.747689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create a custom callback by subclassing the Callback class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ca6f883",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:14:34.237025Z",
     "iopub.status.busy": "2023-02-17T20:14:34.236608Z",
     "iopub.status.idle": "2023-02-17T20:14:34.243978Z",
     "shell.execute_reply": "2023-02-17T20:14:34.243169Z"
    },
    "papermill": {
     "duration": 0.173125,
     "end_time": "2023-02-17T20:14:34.246020",
     "exception": false,
     "start_time": "2023-02-17T20:14:34.072895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        \"\"\"Called at the start of training\"\"\"\n",
    "        self.per_batch_losses = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        \"\"\"Called right after processing each batch\"\"\"\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "        label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b64a027",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:14:34.648903Z",
     "iopub.status.busy": "2023-02-17T20:14:34.647722Z",
     "iopub.status.idle": "2023-02-17T20:16:03.468010Z",
     "shell.execute_reply": "2023-02-17T20:16:03.467161Z"
    },
    "papermill": {
     "duration": 88.990107,
     "end_time": "2023-02-17T20:16:03.470387",
     "exception": false,
     "start_time": "2023-02-17T20:14:34.480280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2917 - accuracy: 0.9144 - val_loss: 0.1496 - val_accuracy: 0.9566\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1620 - accuracy: 0.9542 - val_loss: 0.1314 - val_accuracy: 0.9654\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1390 - accuracy: 0.9629 - val_loss: 0.1093 - val_accuracy: 0.9720\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1225 - accuracy: 0.9680 - val_loss: 0.1131 - val_accuracy: 0.9728\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1173 - accuracy: 0.9702 - val_loss: 0.1129 - val_accuracy: 0.9748\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1115 - accuracy: 0.9727 - val_loss: 0.1127 - val_accuracy: 0.9739\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1066 - accuracy: 0.9748 - val_loss: 0.1032 - val_accuracy: 0.9775\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0983 - accuracy: 0.9770 - val_loss: 0.1072 - val_accuracy: 0.9770\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0976 - accuracy: 0.9779 - val_loss: 0.1143 - val_accuracy: 0.9772\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0965 - accuracy: 0.9788 - val_loss: 0.1108 - val_accuracy: 0.9792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f54a8d9f410>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build the model\n",
    "model = get_mnist_model()\n",
    "\n",
    "# init the model optimizer, loss, metrics\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# train and validate the model\n",
    "model.fit(train_images, train_labels, epochs=10, callbacks=[LossHistory()], validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91521775",
   "metadata": {
    "papermill": {
     "duration": 0.257874,
     "end_time": "2023-02-17T20:16:03.988682",
     "exception": false,
     "start_time": "2023-02-17T20:16:03.730808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Monitoring & Visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a734b91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:16:04.567265Z",
     "iopub.status.busy": "2023-02-17T20:16:04.566560Z",
     "iopub.status.idle": "2023-02-17T20:18:27.155251Z",
     "shell.execute_reply": "2023-02-17T20:18:27.154023Z"
    },
    "papermill": {
     "duration": 143.26582,
     "end_time": "2023-02-17T20:18:27.511086",
     "exception": false,
     "start_time": "2023-02-17T20:16:04.245266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.2925 - accuracy: 0.9137 - val_loss: 0.1487 - val_accuracy: 0.9579\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1643 - accuracy: 0.9536 - val_loss: 0.1193 - val_accuracy: 0.9671\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1362 - accuracy: 0.9634 - val_loss: 0.1137 - val_accuracy: 0.9720\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1241 - accuracy: 0.9681 - val_loss: 0.1130 - val_accuracy: 0.9714\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1172 - accuracy: 0.9701 - val_loss: 0.1123 - val_accuracy: 0.9741\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1126 - accuracy: 0.9727 - val_loss: 0.1085 - val_accuracy: 0.9761\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1088 - accuracy: 0.9751 - val_loss: 0.1095 - val_accuracy: 0.9775\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1009 - accuracy: 0.9770 - val_loss: 0.1190 - val_accuracy: 0.9770\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0961 - accuracy: 0.9781 - val_loss: 0.1177 - val_accuracy: 0.9778\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0942 - accuracy: 0.9780 - val_loss: 0.1231 - val_accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f54a8c5bd90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model\n",
    "model = get_mnist_model()\n",
    "\n",
    "# init the model optimizer, loss, metrics\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "\n",
    "# train and validate the model\n",
    "model.fit(train_images, train_labels,\n",
    "    epochs=10,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cc64bfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:18:28.281429Z",
     "iopub.status.busy": "2023-02-17T20:18:28.280982Z",
     "iopub.status.idle": "2023-02-17T20:18:54.165181Z",
     "shell.execute_reply": "2023-02-17T20:18:54.164143Z"
    },
    "papermill": {
     "duration": 26.303974,
     "end_time": "2023-02-17T20:18:54.167775",
     "exception": false,
     "start_time": "2023-02-17T20:18:27.863801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (2.9.1)\r\n",
      "Collecting protobuf<3.20,>=3.9.2\r\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (2.28.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.6.1)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.48.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.4.6)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (3.4.1)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.21.6)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (2.2.2)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.37.1)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.8.1)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (59.8.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.35.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.7)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard) (6.0.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.11)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.8.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.1.1)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.1)\r\n",
      "Installing collected packages: protobuf\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.20.3\r\n",
      "    Uninstalling protobuf-3.20.3:\r\n",
      "      Successfully uninstalled protobuf-3.20.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tfx-bsl 1.10.1 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.61.0 which is incompatible.\r\n",
      "tfx-bsl 1.10.1 requires pyarrow<7,>=6, but you have pyarrow 9.0.0 which is incompatible.\r\n",
      "tensorflow-transform 1.10.1 requires pyarrow<7,>=6, but you have pyarrow 9.0.0 which is incompatible.\r\n",
      "tensorflow-serving-api 2.10.0 requires tensorflow<3,>=2.10.0, but you have tensorflow 2.9.2 which is incompatible.\r\n",
      "ortools 9.5.2237 requires protobuf>=4.21.5, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "onnx 1.13.0 requires protobuf<4,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "google-cloud-logging 3.2.2 requires google-cloud-core<3.0.0dev,>=2.0.0, but you have google-cloud-core 1.7.3 which is incompatible.\r\n",
      "google-api-core 1.33.0 requires protobuf<4.0.0dev,>=3.20.1, but you have protobuf 3.19.6 which is incompatible.\r\n",
      "gcsfs 2022.8.2 requires fsspec==2022.8.2, but you have fsspec 2023.1.0 which is incompatible.\r\n",
      "apache-beam 2.41.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\r\n",
      "apache-beam 2.41.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 9.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed protobuf-3.19.6\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc2bdcc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:18:54.895544Z",
     "iopub.status.busy": "2023-02-17T20:18:54.895058Z",
     "iopub.status.idle": "2023-02-17T20:19:00.957885Z",
     "shell.execute_reply": "2023-02-17T20:19:00.956486Z"
    },
    "papermill": {
     "duration": 6.431041,
     "end_time": "2023-02-17T20:19:00.960898",
     "exception": false,
     "start_time": "2023-02-17T20:18:54.529857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-914b96baa2b7e0e9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-914b96baa2b7e0e9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3254805f",
   "metadata": {
    "papermill": {
     "duration": 0.360526,
     "end_time": "2023-02-17T20:19:01.677206",
     "exception": false,
     "start_time": "2023-02-17T20:19:01.316680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## D. Write your own training & evaluation loop\n",
    "- The function fit() will not work for task with no explicit targets are presented such as gneerative learning, self-supervised learning, or reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169fd517",
   "metadata": {
    "papermill": {
     "duration": 0.35279,
     "end_time": "2023-02-17T20:19:02.444538",
     "exception": false,
     "start_time": "2023-02-17T20:19:02.091748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### A step-by-step training loop - fit() with many features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c91502f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:19:03.159731Z",
     "iopub.status.busy": "2023-02-17T20:19:03.158934Z",
     "iopub.status.idle": "2023-02-17T20:19:03.212624Z",
     "shell.execute_reply": "2023-02-17T20:19:03.211381Z"
    },
    "papermill": {
     "duration": 0.415928,
     "end_time": "2023-02-17T20:19:03.215261",
     "exception": false,
     "start_time": "2023-02-17T20:19:02.799333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "# loss function\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# optimizer\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "\n",
    "# list of metrics to monitor\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "\n",
    "# list of metrics to track the loss average\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    \n",
    "    # keep track of metrics\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "        \n",
    "    # keep track of loss average\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    \n",
    "    # return the current values of the metrics and loss\n",
    "    return logs\n",
    "\n",
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80c63e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:19:03.985389Z",
     "iopub.status.busy": "2023-02-17T20:19:03.984601Z",
     "iopub.status.idle": "2023-02-17T20:20:46.781246Z",
     "shell.execute_reply": "2023-02-17T20:20:46.779975Z"
    },
    "papermill": {
     "duration": 103.567903,
     "end_time": "2023-02-17T20:20:47.138629",
     "exception": false,
     "start_time": "2023-02-17T20:19:03.570726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9124\n",
      "...loss: 0.2924\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9535\n",
      "...loss: 0.1649\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9625\n",
      "...loss: 0.1429\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e66ee",
   "metadata": {
    "papermill": {
     "duration": 0.412279,
     "end_time": "2023-02-17T20:20:47.907307",
     "exception": false,
     "start_time": "2023-02-17T20:20:47.495028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### A step-by-step evaluation loop - evaluate() with many features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf2ceb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:20:48.622120Z",
     "iopub.status.busy": "2023-02-17T20:20:48.621698Z",
     "iopub.status.idle": "2023-02-17T20:20:50.621468Z",
     "shell.execute_reply": "2023-02-17T20:20:50.620336Z"
    },
    "papermill": {
     "duration": 2.358806,
     "end_time": "2023-02-17T20:20:50.624431",
     "exception": false,
     "start_time": "2023-02-17T20:20:48.265625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9683\n",
      "...val_loss: 0.1295\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "    \n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "    \n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb3edf",
   "metadata": {
    "papermill": {
     "duration": 0.360924,
     "end_time": "2023-02-17T20:20:51.343342",
     "exception": false,
     "start_time": "2023-02-17T20:20:50.982418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Make it fast with tf.function\n",
    "- Note that the customed fit() and evaluate() function is slower despeite the same logic. This is because TF code is executed line by line. It's more performant to compile your TF code into a computation graph that can be globally optimized in a way that code interpreted line by line can't. We can do this by using a decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5c0e83e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:20:52.120442Z",
     "iopub.status.busy": "2023-02-17T20:20:52.119302Z",
     "iopub.status.idle": "2023-02-17T20:20:53.439791Z",
     "shell.execute_reply": "2023-02-17T20:20:53.438256Z"
    },
    "papermill": {
     "duration": 1.680385,
     "end_time": "2023-02-17T20:20:53.442569",
     "exception": false,
     "start_time": "2023-02-17T20:20:51.762184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9683\n",
      "...val_loss: 0.1295\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "    \n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "    \n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e39bfb1",
   "metadata": {
    "papermill": {
     "duration": 0.356017,
     "end_time": "2023-02-17T20:20:54.157355",
     "exception": false,
     "start_time": "2023-02-17T20:20:53.801338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Leveraging fit() with a custom training loop\n",
    "- When writing your customed training and evaluation loop from scratch, you will have to write a lot of code. What if you want to leverage the power of built-in Keras trainning logic? There is a way: you can provide a custom training step function and let the framework do the rest.\n",
    "- To do this, you will have to overrite the train_step() of the Model class.\n",
    "- Steps:\n",
    "    - Create a new class of subclasses keras.Model\n",
    "    - Overrite the method train_step(self, data.\n",
    "    - Implement a metrics property that tracks the model's Metric instances, this enables the model to automatically call reset_state() on the model's metricsat the start of each epoch and at the start of each epoch and at the start of a call to evalute(), so you don't have to do it by hand.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a35fbd48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:20:54.943452Z",
     "iopub.status.busy": "2023-02-17T20:20:54.942622Z",
     "iopub.status.idle": "2023-02-17T20:20:54.955401Z",
     "shell.execute_reply": "2023-02-17T20:20:54.954233Z"
    },
    "papermill": {
     "duration": 0.437545,
     "end_time": "2023-02-17T20:20:54.958434",
     "exception": false,
     "start_time": "2023-02-17T20:20:54.520889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# metric object to track the average of per-batch losses during training and evaluation.\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        \"\"\"Override the train_step method\"\"\"\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        \n",
    "        # update the loss tracker metrics that tracks the average of the loss\n",
    "        loss_tracker.update_state(loss)\n",
    "        \n",
    "        # return the average loss \n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c031815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:20:55.691161Z",
     "iopub.status.busy": "2023-02-17T20:20:55.689949Z",
     "iopub.status.idle": "2023-02-17T20:21:37.253457Z",
     "shell.execute_reply": "2023-02-17T20:21:37.252355Z"
    },
    "papermill": {
     "duration": 42.317447,
     "end_time": "2023-02-17T20:21:37.643998",
     "exception": false,
     "start_time": "2023-02-17T20:20:55.326551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2929\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1667\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f54a9e49b50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cf2f6a",
   "metadata": {
    "papermill": {
     "duration": 0.383423,
     "end_time": "2023-02-17T20:21:38.474313",
     "exception": false,
     "start_time": "2023-02-17T20:21:38.090890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Note**: What about configure the metrics and the loss via compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67040771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:21:39.241919Z",
     "iopub.status.busy": "2023-02-17T20:21:39.241483Z",
     "iopub.status.idle": "2023-02-17T20:21:39.249030Z",
     "shell.execute_reply": "2023-02-17T20:21:39.247847Z"
    },
    "papermill": {
     "duration": 0.393012,
     "end_time": "2023-02-17T20:21:39.251316",
     "exception": false,
     "start_time": "2023-02-17T20:21:38.858304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "223469df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T20:21:40.084122Z",
     "iopub.status.busy": "2023-02-17T20:21:40.083397Z",
     "iopub.status.idle": "2023-02-17T20:22:04.345731Z",
     "shell.execute_reply": "2023-02-17T20:22:04.344804Z"
    },
    "papermill": {
     "duration": 24.712018,
     "end_time": "2023-02-17T20:22:04.348185",
     "exception": false,
     "start_time": "2023-02-17T20:21:39.636167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2959 - sparse_categorical_accuracy: 0.9130\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1707 - sparse_categorical_accuracy: 0.9532\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1391 - sparse_categorical_accuracy: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5543e43910>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 631.8975,
   "end_time": "2023-02-17T20:22:07.492007",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-17T20:11:35.594507",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e4acf3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.007589,
     "end_time": "2023-02-22T03:37:59.329936",
     "exception": false,
     "start_time": "2023-02-22T03:37:59.322347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 11.2 Preparing Text Data\n",
    "- We can use TextVectorization in Keras.\n",
    "- There are 3 steps in vectorization:\n",
    "    - Standardization.\n",
    "    - Split (Tokenize).\n",
    "    - Indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e33c366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T03:37:59.339597Z",
     "iopub.status.busy": "2023-02-22T03:37:59.338283Z",
     "iopub.status.idle": "2023-02-22T03:38:07.552993Z",
     "shell.execute_reply": "2023-02-22T03:38:07.551531Z"
    },
    "papermill": {
     "duration": 8.222841,
     "end_time": "2023-02-22T03:38:07.556129",
     "exception": false,
     "start_time": "2023-02-22T03:37:59.333288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "917b1411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T03:38:07.565007Z",
     "iopub.status.busy": "2023-02-22T03:38:07.564183Z",
     "iopub.status.idle": "2023-02-22T03:38:07.570996Z",
     "shell.execute_reply": "2023-02-22T03:38:07.569806Z"
    },
    "papermill": {
     "duration": 0.013728,
     "end_time": "2023-02-22T03:38:07.573257",
     "exception": false,
     "start_time": "2023-02-22T03:38:07.559529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_standardization_fn(string_tensor):\n",
    "    # convert to lower case\n",
    "    lowercase_string = tf.strings.lower(string_tensor)\n",
    "    \n",
    "    # replace punctuation character with empty string\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
    "    )\n",
    "\n",
    "def custom_split_fn(string_tensor):\n",
    "    # split strings on whitespaces\n",
    "    return tf.strings.split(string_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab47cc48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T03:38:07.581240Z",
     "iopub.status.busy": "2023-02-22T03:38:07.580796Z",
     "iopub.status.idle": "2023-02-22T03:38:07.663027Z",
     "shell.execute_reply": "2023-02-22T03:38:07.662067Z"
    },
    "papermill": {
     "duration": 0.089776,
     "end_time": "2023-02-22T03:38:07.666283",
     "exception": false,
     "start_time": "2023-02-22T03:38:07.576507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 03:38:07.620965: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64::/opt/conda/lib\n",
      "2023-02-22 03:38:07.621043: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    output_mode=\"int\",\n",
    "    standardize=custom_standardization_fn,\n",
    "    split=custom_split_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2e9a78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T03:38:07.675124Z",
     "iopub.status.busy": "2023-02-22T03:38:07.674438Z",
     "iopub.status.idle": "2023-02-22T03:38:07.679851Z",
     "shell.execute_reply": "2023-02-22T03:38:07.678627Z"
    },
    "papermill": {
     "duration": 0.012923,
     "end_time": "2023-02-22T03:38:07.682691",
     "exception": false,
     "start_time": "2023-02-22T03:38:07.669768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = [\n",
    " \"I write, erase, rewrite\",\n",
    " \"Erase again, and then\",\n",
    " \"A poppy blooms.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7daf9ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T03:38:07.691573Z",
     "iopub.status.busy": "2023-02-22T03:38:07.690534Z",
     "iopub.status.idle": "2023-02-22T03:38:08.033805Z",
     "shell.execute_reply": "2023-02-22T03:38:08.032454Z"
    },
    "papermill": {
     "duration": 0.350654,
     "end_time": "2023-02-22T03:38:08.036675",
     "exception": false,
     "start_time": "2023-02-22T03:38:07.686021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adapt to the dataset\n",
    "text_vectorization.adapt(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c56937f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T03:38:08.045917Z",
     "iopub.status.busy": "2023-02-22T03:38:08.045482Z",
     "iopub.status.idle": "2023-02-22T03:38:08.055680Z",
     "shell.execute_reply": "2023-02-22T03:38:08.054690Z"
    },
    "papermill": {
     "duration": 0.01755,
     "end_time": "2023-02-22T03:38:08.057857",
     "exception": false,
     "start_time": "2023-02-22T03:38:08.040307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'erase',\n",
       " 'write',\n",
       " 'then',\n",
       " 'rewrite',\n",
       " 'poppy',\n",
       " 'i',\n",
       " 'blooms',\n",
       " 'and',\n",
       " 'again',\n",
       " 'a']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display vocabilary\n",
    "text_vectorization.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0696cbfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T03:38:08.067320Z",
     "iopub.status.busy": "2023-02-22T03:38:08.066136Z",
     "iopub.status.idle": "2023-02-22T03:38:08.138067Z",
     "shell.execute_reply": "2023-02-22T03:38:08.136722Z"
    },
    "papermill": {
     "duration": 0.079549,
     "end_time": "2023-02-22T03:38:08.140949",
     "exception": false,
     "start_time": "2023-02-22T03:38:08.061400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# let's go thru example of encode and decode a sentence\n",
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
    "encoded_sentence = text_vectorization(test_sentence)\n",
    "print(encoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "082f5552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T03:38:08.150099Z",
     "iopub.status.busy": "2023-02-22T03:38:08.149634Z",
     "iopub.status.idle": "2023-02-22T03:38:08.160359Z",
     "shell.execute_reply": "2023-02-22T03:38:08.158873Z"
    },
    "papermill": {
     "duration": 0.018153,
     "end_time": "2023-02-22T03:38:08.162905",
     "exception": false,
     "start_time": "2023-02-22T03:38:08.144752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i write rewrite and [UNK] rewrite again\n"
     ]
    }
   ],
   "source": [
    "inverse_vocab = dict(enumerate(vocabulary))\n",
    "decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n",
    "print(decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.971969,
   "end_time": "2023-02-22T03:38:11.094013",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-22T03:37:49.122044",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

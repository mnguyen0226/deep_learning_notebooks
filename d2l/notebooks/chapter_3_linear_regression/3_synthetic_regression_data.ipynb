{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26510ca6-b56e-435b-b53f-5e7285b40d22",
   "metadata": {},
   "source": [
    "# 3. Synthetic Regression Data\n",
    "Synthetic data does not have patterns. However, it is for didatic purposes, helping us to evaluate the properties of our learning algo and to confirm that our implementations works as expected. For example, if we create data fro which the correct params are know a priori, then we can check the model can infact recovert them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a8aafb0-c80c-42c9-ab0e-4725d2722625",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310f4f29-2a82-4fb5-a324-a478efaac329",
   "metadata": {},
   "source": [
    "## Generate Dataset\n",
    "1000 examples with 2D features drawn from a standard normal distribution\n",
    "\n",
    "Note that we have the ground truth w = [2, -3.4] and b = 4.2. Later we can check our estimated parameters against these ground truth values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab927d53-2c10-476a-b637-8da4ff84b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticRegressionData(d2l.DataModule):  #@save\n",
    "    \"\"\"Synthetic data for linear regression.\"\"\"\n",
    "    def __init__(self, w, b, noise=0.01, num_train=1000, num_val=1000,\n",
    "                 batch_size=32):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        n = num_train + num_val\n",
    "        self.X = torch.randn(n, len(w))\n",
    "        noise = torch.randn(n, 1) * noise\n",
    "        self.y = torch.matmul(self.X, w.reshape((-1, 1))) + b + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "231d5aaf-4161-4c7e-ba47-c39212268df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SyntheticRegressionData(w=torch.tensor([2, -3.4]), b=4.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b305d4-ce76-4061-85a5-e2934ac6fc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([ 0.4505, -0.9686]) \n",
      "label: tensor([8.3928])\n"
     ]
    }
   ],
   "source": [
    "print('features:', data.X[0],'\\nlabel:', data.y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0dd52e-36e7-4630-9449-b08609349629",
   "metadata": {},
   "source": [
    "## Reading the Dataset\n",
    "Training ML models often requires multiple passes over a dataset, grabbing one minbatch of examples at a time. The data is then used to update the model.\n",
    "\n",
    "Each minibatch consists of a tuple of features and labels.\n",
    "\n",
    "Note that we need to be mindful of whether we are in training or validation mode\n",
    "- Training: we will want to read data in random roder\n",
    "- Validation: read data in predefined order for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cdba93b-83b5-422c-896d-b5fa14a65e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement get_dataloader(), registering it in class via add_to_class - this is decorator\n",
    "@d2l.add_to_class(SyntheticRegressionData)\n",
    "def get_dataloader(self, train):\n",
    "    if train:\n",
    "        indices = list(range(0, self.num_train))\n",
    "        # The examples are read in random order\n",
    "        random.shuffle(indices)\n",
    "    else:\n",
    "        indices = list(range(self.num_train, self.num_train+self.num_val))\n",
    "    for i in range(0, len(indices), self.batch_size):\n",
    "        batch_indices = torch.tensor(indices[i: i+self.batch_size])\n",
    "        yield self.X[batch_indices], self.y[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3af4a257-0a54-4299-96ec-a2b7b22f0776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([32, 2]) \n",
      "y shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# This function is inherit from d2l.DataModule\n",
    "X, y = next(iter(data.train_dataloader()))\n",
    "print('X shape:', X.shape, '\\ny shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075cdb9-96b2-48da-baf0-ee0040cda319",
   "metadata": {},
   "source": [
    "This implemenetation is problem as it requires we load all the data in memory and that we perfomr lots of random memeory access.\n",
    "\n",
    "Thus, we shouldd us iterator so that they can deal with sources in files, stream or data generated or processes on the fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5580ea2-47f8-4def-b15c-4e2d42ba7aab",
   "metadata": {},
   "source": [
    "## Concise Implementation of the Data Loader\n",
    "- More efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c194488-4c2e-4eb2-8e8e-4e93eccf599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(d2l.DataModule)  #@save\n",
    "def get_tensorloader(self, tensors, train, indices=slice(0, None)):\n",
    "    tensors = tuple(a[indices] for a in tensors)\n",
    "    dataset = torch.utils.data.TensorDataset(*tensors)\n",
    "    return torch.utils.data.DataLoader(dataset, self.batch_size,\n",
    "                                       shuffle=train)\n",
    "\n",
    "@d2l.add_to_class(SyntheticRegressionData)  #@save\n",
    "def get_dataloader(self, train):\n",
    "    i = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
    "    return self.get_tensorloader((self.X, self.y), train, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc607af-eece-4538-8d00-fc20a9f993ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([32, 2]) \n",
      "y shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(data.train_dataloader()))\n",
    "print('X shape:', X.shape, '\\ny shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f15f9d-b174-4bb6-baf0-1f59efd503bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff61799-f935-4af6-a042-3d14d32dac28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

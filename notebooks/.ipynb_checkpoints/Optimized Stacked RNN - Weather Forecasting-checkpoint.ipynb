{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd440a0",
   "metadata": {},
   "source": [
    "# Time-series Forecasting For Weather Station - Stacked Recurrent Network\n",
    "- About: 14 attributes, 10 minutes interval in several years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90bdb44",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b980b6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n",
      "420451\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "fname = os.path.join(\"data/jena_climate_2009_2016.csv\")\n",
    "\n",
    "# Open the file and read the header\n",
    "with open(fname) as f:\n",
    "    data = f.read()\n",
    "    \n",
    "lines = data.split(\"\\n\") # split all the rows\n",
    "header = lines[0].split(\",\")\n",
    "lines = lines[1:] # don't get the title column\n",
    "print(header)\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa446647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create an array for temperature with the number of rows\n",
    "temperature = np.zeros((len(lines),))\n",
    "\n",
    "# Create an array of tuples\n",
    "raw_data = np.zeros((len(lines), len(header) - 1))\n",
    "\n",
    "# Go thru each lines and store in our array\n",
    "for i, line in enumerate(lines):\n",
    "    # Split the row into individual values except for datetime\n",
    "    values = [float(x) for x in line.split(\",\")[1:]] \n",
    "    temperature[i] = values[1] # get the temp\n",
    "    raw_data[i, :] = values[:] # store everything, including the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b21565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_samples: 210225\n",
      "num_val_samples: 105112\n",
      "num_test_samples: 105114\n"
     ]
    }
   ],
   "source": [
    "num_train_samples = int(0.5 * len(raw_data))\n",
    "num_val_samples = int(0.25 * len(raw_data))\n",
    "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
    "print(f\"num_train_samples: {num_train_samples}\")\n",
    "print(f\"num_val_samples: {num_val_samples}\")\n",
    "print(f\"num_test_samples: {num_test_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "299cf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = raw_data[:num_train_samples].mean(axis=0)\n",
    "raw_data -= mean\n",
    "std = raw_data[:num_train_samples].std(axis=0)\n",
    "raw_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9deec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 22:45:36.843412: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-12 22:45:36.845020: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-12 22:45:36.874649: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-12 22:45:36.875000: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-12 22:45:37.386518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mnguyen0226/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/mnguyen0226/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "sampling_rate = 6 # once every hour\n",
    "sequence_length = 120 # 5 x 24 = 5 days = 120 hours\n",
    "delay = sampling_rate * (sequence_length + 24 - 1)\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=0,\n",
    "    end_index=num_train_samples\n",
    ")\n",
    "\n",
    "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples,\n",
    "    end_index=num_train_samples + num_val_samples\n",
    ")\n",
    "\n",
    "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples + num_val_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b169b546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples shape: (256, 120, 14)\n",
      "targets shape: (256,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 22:45:47.196978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_28' with dtype int32 and shape [209506]\n",
      "\t [[{{node Placeholder/_28}}]]\n",
      "2024-03-12 22:45:47.197584: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [210225,14]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "for samples, targets in train_dataset:\n",
    "    print(f\"samples shape: {samples.shape}\")\n",
    "    print(f\"targets shape: {targets.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99231bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 27/819 [..............................] - ETA: 1:42 - loss: 103.1662 - mae: 8.5395"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = layers.GRU(32, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
    "x = layers.GRU(32, recurrent_dropout=0.5)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"models/jena_stacked_gru_dropout_optimized.keras\", save_best_only=True)\n",
    "]\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "history = model.fit(train_dataset, epochs=15, validation_data=val_dataset, callbacks=callbacks)\n",
    "model = keras.models.load_model(\"models/jena_stacked_gru_dropout_optimized.keras\")\n",
    "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bdfcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from tensorflow import keras\n",
    "\n",
    "# Step 1: Load the trained model\n",
    "model = keras.models.load_model(\"models/jena_stacked_gru_dropout_optimized.keras\")\n",
    "\n",
    "# Step 2 and 3: Prepare input and make predictions\n",
    "# Assuming you want to predict for the first few days in your test dataset\n",
    "num_days_to_predict = 7  # Number of days to predict\n",
    "num_predictions = num_days_to_predict * 24 * (60 // sampling_rate)  # Predict every hour, adjust depending on your data's time resolution\n",
    "\n",
    "predicted_temperatures = []\n",
    "actual_temperatures = []\n",
    "for batch in test_dataset.take(num_days_to_predict):  # Assuming each batch is a day, adjust if necessary\n",
    "    inputs, targets = batch\n",
    "    predictions = model.predict(inputs).flatten()\n",
    "    predicted_temperatures.extend(predictions[:num_predictions])\n",
    "    actual_temperatures.extend(targets.numpy()[:num_predictions])\n",
    "\n",
    "# Step 4: Plot actual vs. predicted temperature using Plotly\n",
    "actual_trace = go.Scatter(\n",
    "    x=list(range(num_predictions)),\n",
    "    y=actual_temperatures,\n",
    "    mode='lines',\n",
    "    name='Actual Temperature'\n",
    ")\n",
    "\n",
    "predicted_trace = go.Scatter(\n",
    "    x=list(range(num_predictions)),\n",
    "    y=predicted_temperatures,\n",
    "    mode='lines',\n",
    "    name='Predicted Temperature'\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Actual vs Predicted Temperature',\n",
    "    xaxis={'title': 'Time'},\n",
    "    yaxis={'title': 'Temperature (normalized)'}\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[actual_trace, predicted_trace], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2795bb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
